<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Louis Tiao (Posts about unsupervised learning)</title><link>http://louistiao.me/</link><description></description><atom:link href="http://louistiao.me/tags/unsupervised-learning.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><copyright>Contents Â© 2017 &lt;a href="mailto:louistiao@me.com"&gt;Louis Tiao&lt;/a&gt; </copyright><lastBuildDate>Thu, 23 Nov 2017 07:13:08 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Inference in Variational Autoencoders with Different Monte Carlo Sample Sizes</title><link>http://louistiao.me/posts/inference-in-variational-autoencoders-with-different-monte-carlo-sample-sizes/</link><dc:creator>Louis Tiao</dc:creator><description>&lt;div&gt;&lt;div class="admonition admonition-draft"&gt;
&lt;p class="first admonition-title"&gt;Draft&lt;/p&gt;
&lt;p class="last"&gt;Please do not share or link.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;In a &lt;a class="reference external" href="http://louistiao.me/posts/implementing-variational-autoencoders-in-keras-beyond-the-quickstart-tutorial/"&gt;previous post&lt;/a&gt;,
I demonstrated how to use leverage Keras' modular design to implement variational
inference in a way that makes it easy to tweak hyperparameters, adapt to related
models, and extend to the more sophisticated methods in the current research.&lt;/p&gt;
&lt;pre class="code python"&gt;&lt;a name="rest_code_e08dcc20d2f64c4e8b36b8bfd3ee19c9-1"&gt;&lt;/a&gt;&lt;span class="n"&gt;eps&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Input&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;mc_samples&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;latent_dim&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;p&gt;Everything else remains exactly the same. The &lt;tt class="docutils literal"&gt;Multiply&lt;/tt&gt; layer will
automatically broadcast &lt;tt class="docutils literal"&gt;eps&lt;/tt&gt; which has shape
&lt;tt class="docutils literal"&gt;(batch_size, mc_samples, latent_dim)&lt;/tt&gt; with &lt;tt class="docutils literal"&gt;sigma&lt;/tt&gt; which has shape
&lt;tt class="docutils literal"&gt;(batch_size, latent_dim)&lt;/tt&gt; and output shape
&lt;tt class="docutils literal"&gt;(batch_size, mc_samples, latent_dim)&lt;/tt&gt;. Since the subsequent layers do not
operate on the which will then be propagated to the
final output.&lt;/p&gt;
&lt;div class="figure align-center"&gt;
&lt;object data="http://louistiao.me/images/vae/reparameterization_mc_samples_shapes.svg" style="width: 600px;" type="image/svg+xml"&gt;
../../images/vae/reparameterization_mc_samples_shapes.svg&lt;/object&gt;
&lt;p class="caption"&gt;Reparameterization with simple location-scale transformation using Keras
merge layers.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="figure align-center"&gt;
&lt;object data="http://louistiao.me/images/vae/vae_full_mc_samples_shapes.svg" style="width: 600px;" type="image/svg+xml"&gt;
../../images/vae/vae_full_mc_samples_shapes.svg&lt;/object&gt;
&lt;p class="caption"&gt;Reparameterization with simple location-scale transformation using Keras
merge layers.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;We expand the targets to 3d a array &lt;tt class="docutils literal"&gt;np.expand_dims(x_train, axis=1)&lt;/tt&gt; to be
of shape &lt;tt class="docutils literal"&gt;(batch_size, 1, original_dim)&lt;/tt&gt; so that the loss function can
broadcast with the output with shape &lt;tt class="docutils literal"&gt;(batch_size, mc_samples, original_dim)&lt;/tt&gt;.
It is important to make the distinction between the log likelihood of the mean
over outputs, versus the mean of the log likelihood over the outputs. Since we
require the expected log likelihood, we are interested in the latter.&lt;/p&gt;
&lt;pre class="code python"&gt;&lt;a name="rest_code_048c776273664ed9a798362aa62806fc-1"&gt;&lt;/a&gt;&lt;span class="n"&gt;eps_train&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;randn&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x_train&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;mc_samples&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;latent_dim&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_048c776273664ed9a798362aa62806fc-2"&gt;&lt;/a&gt;&lt;span class="n"&gt;eps_test&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;randn&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x_test&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;mc_samples&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;latent_dim&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_048c776273664ed9a798362aa62806fc-3"&gt;&lt;/a&gt;
&lt;a name="rest_code_048c776273664ed9a798362aa62806fc-4"&gt;&lt;/a&gt;&lt;span class="n"&gt;vae&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
&lt;a name="rest_code_048c776273664ed9a798362aa62806fc-5"&gt;&lt;/a&gt;    &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;x_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;eps_train&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
&lt;a name="rest_code_048c776273664ed9a798362aa62806fc-6"&gt;&lt;/a&gt;    &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;expand_dims&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;axis&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
&lt;a name="rest_code_048c776273664ed9a798362aa62806fc-7"&gt;&lt;/a&gt;    &lt;span class="n"&gt;shuffle&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;a name="rest_code_048c776273664ed9a798362aa62806fc-8"&gt;&lt;/a&gt;    &lt;span class="n"&gt;epochs&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;epochs&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;a name="rest_code_048c776273664ed9a798362aa62806fc-9"&gt;&lt;/a&gt;    &lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;a name="rest_code_048c776273664ed9a798362aa62806fc-10"&gt;&lt;/a&gt;    &lt;span class="n"&gt;validation_data&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
&lt;a name="rest_code_048c776273664ed9a798362aa62806fc-11"&gt;&lt;/a&gt;        &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;x_test&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;eps_test&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
&lt;a name="rest_code_048c776273664ed9a798362aa62806fc-12"&gt;&lt;/a&gt;        &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;expand_dims&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x_test&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;axis&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_048c776273664ed9a798362aa62806fc-13"&gt;&lt;/a&gt;    &lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_048c776273664ed9a798362aa62806fc-14"&gt;&lt;/a&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;p&gt;For every data point, there are &lt;tt class="docutils literal"&gt;mc_samples&lt;/tt&gt; reconstructions.&lt;/p&gt;
&lt;pre class="code python"&gt;&lt;a name="rest_code_95e1083032e143758ee58b01409415fa-1"&gt;&lt;/a&gt;&lt;span class="n"&gt;recons&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;vae&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;x_test&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;eps_test&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]])&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;squeeze&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;a name="rest_code_95e1083032e143758ee58b01409415fa-2"&gt;&lt;/a&gt;
&lt;a name="rest_code_95e1083032e143758ee58b01409415fa-3"&gt;&lt;/a&gt;&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;figure&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;figsize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;a name="rest_code_95e1083032e143758ee58b01409415fa-4"&gt;&lt;/a&gt;&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;imshow&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;block&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;list&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;map&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;list&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;recons&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reshape&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;28&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;28&lt;/span&gt;&lt;span class="p"&gt;)))),&lt;/span&gt;
&lt;a name="rest_code_95e1083032e143758ee58b01409415fa-5"&gt;&lt;/a&gt;           &lt;span class="n"&gt;cmap&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'gray'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_95e1083032e143758ee58b01409415fa-6"&gt;&lt;/a&gt;&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;show&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;p&gt;plot here&lt;/p&gt;
&lt;div class="section" id="appendix"&gt;
&lt;h2&gt;Appendix&lt;/h2&gt;
&lt;p&gt;Below you can find:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;The &lt;a class="reference external" href="http://louistiao.me/listings/vae/variational_autoencoder_mc_samples.ipynb.html"&gt;accompanying Jupyter Notebook&lt;/a&gt; used to generate the diagrams and plots
in this post.&lt;/li&gt;
&lt;li&gt;The above snippets combined in a single executable Python file:&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a class="reference external" href="http://louistiao.me/listings/vae/variational_autoencoder_mc_samples.py.html"&gt;vae/variational_autoencoder_mc_samples.py&lt;/a&gt;  &lt;a class="reference external" href="http://louistiao.me/listings/vae/variational_autoencoder_mc_samples.py"&gt;(Source)&lt;/a&gt;&lt;/p&gt;
&lt;pre class="code python"&gt;&lt;a name="rest_code_c95e602ed3524487b8013ace0aa1a044-1"&gt;&lt;/a&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
&lt;a name="rest_code_c95e602ed3524487b8013ace0aa1a044-2"&gt;&lt;/a&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;plt&lt;/span&gt;
&lt;a name="rest_code_c95e602ed3524487b8013ace0aa1a044-3"&gt;&lt;/a&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;scipy.stats&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;norm&lt;/span&gt;
&lt;a name="rest_code_c95e602ed3524487b8013ace0aa1a044-4"&gt;&lt;/a&gt;
&lt;a name="rest_code_c95e602ed3524487b8013ace0aa1a044-5"&gt;&lt;/a&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;keras&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;backend&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;K&lt;/span&gt;
&lt;a name="rest_code_c95e602ed3524487b8013ace0aa1a044-6"&gt;&lt;/a&gt;
&lt;a name="rest_code_c95e602ed3524487b8013ace0aa1a044-7"&gt;&lt;/a&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;keras.layers&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Input&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Dense&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Lambda&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Layer&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Add&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Multiply&lt;/span&gt;
&lt;a name="rest_code_c95e602ed3524487b8013ace0aa1a044-8"&gt;&lt;/a&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;keras.models&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Model&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Sequential&lt;/span&gt;
&lt;a name="rest_code_c95e602ed3524487b8013ace0aa1a044-9"&gt;&lt;/a&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;keras.datasets&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;mnist&lt;/span&gt;
&lt;a name="rest_code_c95e602ed3524487b8013ace0aa1a044-10"&gt;&lt;/a&gt;
&lt;a name="rest_code_c95e602ed3524487b8013ace0aa1a044-11"&gt;&lt;/a&gt;
&lt;a name="rest_code_c95e602ed3524487b8013ace0aa1a044-12"&gt;&lt;/a&gt;&lt;span class="n"&gt;batch_size&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt;
&lt;a name="rest_code_c95e602ed3524487b8013ace0aa1a044-13"&gt;&lt;/a&gt;&lt;span class="n"&gt;original_dim&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;784&lt;/span&gt;
&lt;a name="rest_code_c95e602ed3524487b8013ace0aa1a044-14"&gt;&lt;/a&gt;&lt;span class="n"&gt;latent_dim&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;
&lt;a name="rest_code_c95e602ed3524487b8013ace0aa1a044-15"&gt;&lt;/a&gt;&lt;span class="n"&gt;intermediate_dim&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;256&lt;/span&gt;
&lt;a name="rest_code_c95e602ed3524487b8013ace0aa1a044-16"&gt;&lt;/a&gt;&lt;span class="n"&gt;epochs&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;50&lt;/span&gt;
&lt;a name="rest_code_c95e602ed3524487b8013ace0aa1a044-17"&gt;&lt;/a&gt;&lt;span class="n"&gt;epsilon_std&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;1.0&lt;/span&gt;
&lt;a name="rest_code_c95e602ed3524487b8013ace0aa1a044-18"&gt;&lt;/a&gt;
&lt;a name="rest_code_c95e602ed3524487b8013ace0aa1a044-19"&gt;&lt;/a&gt;
&lt;a name="rest_code_c95e602ed3524487b8013ace0aa1a044-20"&gt;&lt;/a&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;nll&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y_true&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_pred&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;a name="rest_code_c95e602ed3524487b8013ace0aa1a044-21"&gt;&lt;/a&gt;    &lt;span class="sd"&gt;""" Bernoulli negative log likelihood. """&lt;/span&gt;
&lt;a name="rest_code_c95e602ed3524487b8013ace0aa1a044-22"&gt;&lt;/a&gt;
&lt;a name="rest_code_c95e602ed3524487b8013ace0aa1a044-23"&gt;&lt;/a&gt;    &lt;span class="c1"&gt;# keras.losses.binary_crossentropy gives the mean&lt;/span&gt;
&lt;a name="rest_code_c95e602ed3524487b8013ace0aa1a044-24"&gt;&lt;/a&gt;    &lt;span class="c1"&gt;# over the last axis. We require the sum.&lt;/span&gt;
&lt;a name="rest_code_c95e602ed3524487b8013ace0aa1a044-25"&gt;&lt;/a&gt;    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;K&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;K&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;binary_crossentropy&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y_true&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_pred&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;axis&lt;/span&gt;&lt;span class="o"&gt;=-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_c95e602ed3524487b8013ace0aa1a044-26"&gt;&lt;/a&gt;
&lt;a name="rest_code_c95e602ed3524487b8013ace0aa1a044-27"&gt;&lt;/a&gt;
&lt;a name="rest_code_c95e602ed3524487b8013ace0aa1a044-28"&gt;&lt;/a&gt;&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;KLDivergenceLayer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Layer&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;a name="rest_code_c95e602ed3524487b8013ace0aa1a044-29"&gt;&lt;/a&gt;
&lt;a name="rest_code_c95e602ed3524487b8013ace0aa1a044-30"&gt;&lt;/a&gt;    &lt;span class="sd"&gt;""" Identity transform layer that adds KL divergence&lt;/span&gt;
&lt;a name="rest_code_c95e602ed3524487b8013ace0aa1a044-31"&gt;&lt;/a&gt;&lt;span class="sd"&gt;    to the final model loss.&lt;/span&gt;
&lt;a name="rest_code_c95e602ed3524487b8013ace0aa1a044-32"&gt;&lt;/a&gt;&lt;span class="sd"&gt;    """&lt;/span&gt;
&lt;a name="rest_code_c95e602ed3524487b8013ace0aa1a044-33"&gt;&lt;/a&gt;
&lt;a name="rest_code_c95e602ed3524487b8013ace0aa1a044-34"&gt;&lt;/a&gt;    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="fm"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;kwargs&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;a name="rest_code_c95e602ed3524487b8013ace0aa1a044-35"&gt;&lt;/a&gt;        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;is_placeholder&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;True&lt;/span&gt;
&lt;a name="rest_code_c95e602ed3524487b8013ace0aa1a044-36"&gt;&lt;/a&gt;        &lt;span class="nb"&gt;super&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;KLDivergenceLayer&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="fm"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;kwargs&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_c95e602ed3524487b8013ace0aa1a044-37"&gt;&lt;/a&gt;
&lt;a name="rest_code_c95e602ed3524487b8013ace0aa1a044-38"&gt;&lt;/a&gt;    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;call&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;inputs&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;a name="rest_code_c95e602ed3524487b8013ace0aa1a044-39"&gt;&lt;/a&gt;
&lt;a name="rest_code_c95e602ed3524487b8013ace0aa1a044-40"&gt;&lt;/a&gt;        &lt;span class="n"&gt;mu&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;log_var&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;inputs&lt;/span&gt;
&lt;a name="rest_code_c95e602ed3524487b8013ace0aa1a044-41"&gt;&lt;/a&gt;
&lt;a name="rest_code_c95e602ed3524487b8013ace0aa1a044-42"&gt;&lt;/a&gt;        &lt;span class="n"&gt;kl_batch&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;K&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;log_var&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;
&lt;a name="rest_code_c95e602ed3524487b8013ace0aa1a044-43"&gt;&lt;/a&gt;                                &lt;span class="n"&gt;K&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;square&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;mu&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;
&lt;a name="rest_code_c95e602ed3524487b8013ace0aa1a044-44"&gt;&lt;/a&gt;                                &lt;span class="n"&gt;K&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;exp&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;log_var&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;axis&lt;/span&gt;&lt;span class="o"&gt;=-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_c95e602ed3524487b8013ace0aa1a044-45"&gt;&lt;/a&gt;
&lt;a name="rest_code_c95e602ed3524487b8013ace0aa1a044-46"&gt;&lt;/a&gt;        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add_loss&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;K&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mean&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;kl_batch&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;inputs&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;inputs&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_c95e602ed3524487b8013ace0aa1a044-47"&gt;&lt;/a&gt;
&lt;a name="rest_code_c95e602ed3524487b8013ace0aa1a044-48"&gt;&lt;/a&gt;        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;inputs&lt;/span&gt;
&lt;a name="rest_code_c95e602ed3524487b8013ace0aa1a044-49"&gt;&lt;/a&gt;
&lt;a name="rest_code_c95e602ed3524487b8013ace0aa1a044-50"&gt;&lt;/a&gt;&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Input&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;original_dim&lt;/span&gt;&lt;span class="p"&gt;,))&lt;/span&gt;
&lt;a name="rest_code_c95e602ed3524487b8013ace0aa1a044-51"&gt;&lt;/a&gt;&lt;span class="n"&gt;h&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Dense&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;intermediate_dim&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;activation&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'relu'&lt;/span&gt;&lt;span class="p"&gt;)(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_c95e602ed3524487b8013ace0aa1a044-52"&gt;&lt;/a&gt;
&lt;a name="rest_code_c95e602ed3524487b8013ace0aa1a044-53"&gt;&lt;/a&gt;&lt;span class="n"&gt;z_mu&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Dense&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;latent_dim&lt;/span&gt;&lt;span class="p"&gt;)(&lt;/span&gt;&lt;span class="n"&gt;h&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_c95e602ed3524487b8013ace0aa1a044-54"&gt;&lt;/a&gt;&lt;span class="n"&gt;z_log_var&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Dense&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;latent_dim&lt;/span&gt;&lt;span class="p"&gt;)(&lt;/span&gt;&lt;span class="n"&gt;h&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_c95e602ed3524487b8013ace0aa1a044-55"&gt;&lt;/a&gt;
&lt;a name="rest_code_c95e602ed3524487b8013ace0aa1a044-56"&gt;&lt;/a&gt;&lt;span class="n"&gt;z_mu&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;z_log_var&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;KLDivergenceLayer&lt;/span&gt;&lt;span class="p"&gt;()([&lt;/span&gt;&lt;span class="n"&gt;z_mu&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;z_log_var&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;a name="rest_code_c95e602ed3524487b8013ace0aa1a044-57"&gt;&lt;/a&gt;&lt;span class="n"&gt;z_sigma&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Lambda&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;K&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;exp&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;))(&lt;/span&gt;&lt;span class="n"&gt;z_log_var&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_c95e602ed3524487b8013ace0aa1a044-58"&gt;&lt;/a&gt;
&lt;a name="rest_code_c95e602ed3524487b8013ace0aa1a044-59"&gt;&lt;/a&gt;&lt;span class="n"&gt;eps&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Input&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tensor&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;K&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random_normal&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;K&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;latent_dim&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
&lt;a name="rest_code_c95e602ed3524487b8013ace0aa1a044-60"&gt;&lt;/a&gt;&lt;span class="n"&gt;z_eps&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Multiply&lt;/span&gt;&lt;span class="p"&gt;()([&lt;/span&gt;&lt;span class="n"&gt;z_sigma&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;eps&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;a name="rest_code_c95e602ed3524487b8013ace0aa1a044-61"&gt;&lt;/a&gt;&lt;span class="n"&gt;z&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Add&lt;/span&gt;&lt;span class="p"&gt;()([&lt;/span&gt;&lt;span class="n"&gt;z_mu&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;z_eps&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;a name="rest_code_c95e602ed3524487b8013ace0aa1a044-62"&gt;&lt;/a&gt;
&lt;a name="rest_code_c95e602ed3524487b8013ace0aa1a044-63"&gt;&lt;/a&gt;&lt;span class="n"&gt;decoder&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Sequential&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;
&lt;a name="rest_code_c95e602ed3524487b8013ace0aa1a044-64"&gt;&lt;/a&gt;    &lt;span class="n"&gt;Dense&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;intermediate_dim&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;input_dim&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;latent_dim&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;activation&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'relu'&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
&lt;a name="rest_code_c95e602ed3524487b8013ace0aa1a044-65"&gt;&lt;/a&gt;    &lt;span class="n"&gt;Dense&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;original_dim&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;activation&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'sigmoid'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_c95e602ed3524487b8013ace0aa1a044-66"&gt;&lt;/a&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;a name="rest_code_c95e602ed3524487b8013ace0aa1a044-67"&gt;&lt;/a&gt;
&lt;a name="rest_code_c95e602ed3524487b8013ace0aa1a044-68"&gt;&lt;/a&gt;&lt;span class="n"&gt;x_mean&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;decoder&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;z&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_c95e602ed3524487b8013ace0aa1a044-69"&gt;&lt;/a&gt;
&lt;a name="rest_code_c95e602ed3524487b8013ace0aa1a044-70"&gt;&lt;/a&gt;&lt;span class="n"&gt;vae&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Model&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;inputs&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;eps&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;outputs&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;x_mean&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_c95e602ed3524487b8013ace0aa1a044-71"&gt;&lt;/a&gt;&lt;span class="n"&gt;vae&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;compile&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;optimizer&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'rmsprop'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;loss&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;nll&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_c95e602ed3524487b8013ace0aa1a044-72"&gt;&lt;/a&gt;
&lt;a name="rest_code_c95e602ed3524487b8013ace0aa1a044-73"&gt;&lt;/a&gt;&lt;span class="c1"&gt;# train the VAE on MNIST digits&lt;/span&gt;
&lt;a name="rest_code_c95e602ed3524487b8013ace0aa1a044-74"&gt;&lt;/a&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_train&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x_test&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_test&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;mnist&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;load_data&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;a name="rest_code_c95e602ed3524487b8013ace0aa1a044-75"&gt;&lt;/a&gt;&lt;span class="n"&gt;x_train&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;x_train&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reshape&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;original_dim&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="mf"&gt;255.&lt;/span&gt;
&lt;a name="rest_code_c95e602ed3524487b8013ace0aa1a044-76"&gt;&lt;/a&gt;&lt;span class="n"&gt;x_test&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;x_test&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reshape&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;original_dim&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="mf"&gt;255.&lt;/span&gt;
&lt;a name="rest_code_c95e602ed3524487b8013ace0aa1a044-77"&gt;&lt;/a&gt;
&lt;a name="rest_code_c95e602ed3524487b8013ace0aa1a044-78"&gt;&lt;/a&gt;&lt;span class="n"&gt;vae&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;a name="rest_code_c95e602ed3524487b8013ace0aa1a044-79"&gt;&lt;/a&gt;        &lt;span class="n"&gt;x_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;a name="rest_code_c95e602ed3524487b8013ace0aa1a044-80"&gt;&lt;/a&gt;        &lt;span class="n"&gt;shuffle&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;a name="rest_code_c95e602ed3524487b8013ace0aa1a044-81"&gt;&lt;/a&gt;        &lt;span class="n"&gt;epochs&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;epochs&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;a name="rest_code_c95e602ed3524487b8013ace0aa1a044-82"&gt;&lt;/a&gt;        &lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;a name="rest_code_c95e602ed3524487b8013ace0aa1a044-83"&gt;&lt;/a&gt;        &lt;span class="n"&gt;validation_data&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x_test&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x_test&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;a name="rest_code_c95e602ed3524487b8013ace0aa1a044-84"&gt;&lt;/a&gt;
&lt;a name="rest_code_c95e602ed3524487b8013ace0aa1a044-85"&gt;&lt;/a&gt;&lt;span class="n"&gt;encoder&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Model&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;z_mu&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_c95e602ed3524487b8013ace0aa1a044-86"&gt;&lt;/a&gt;
&lt;a name="rest_code_c95e602ed3524487b8013ace0aa1a044-87"&gt;&lt;/a&gt;&lt;span class="c1"&gt;# display a 2D plot of the digit classes in the latent space&lt;/span&gt;
&lt;a name="rest_code_c95e602ed3524487b8013ace0aa1a044-88"&gt;&lt;/a&gt;&lt;span class="n"&gt;z_test&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;encoder&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x_test&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_c95e602ed3524487b8013ace0aa1a044-89"&gt;&lt;/a&gt;&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;figure&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;figsize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;a name="rest_code_c95e602ed3524487b8013ace0aa1a044-90"&gt;&lt;/a&gt;&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;scatter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;z_test&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;z_test&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;y_test&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;a name="rest_code_c95e602ed3524487b8013ace0aa1a044-91"&gt;&lt;/a&gt;            &lt;span class="n"&gt;alpha&lt;/span&gt;&lt;span class="o"&gt;=.&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;s&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;cmap&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'viridis'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_c95e602ed3524487b8013ace0aa1a044-92"&gt;&lt;/a&gt;&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;colorbar&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;a name="rest_code_c95e602ed3524487b8013ace0aa1a044-93"&gt;&lt;/a&gt;&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;show&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;a name="rest_code_c95e602ed3524487b8013ace0aa1a044-94"&gt;&lt;/a&gt;
&lt;a name="rest_code_c95e602ed3524487b8013ace0aa1a044-95"&gt;&lt;/a&gt;&lt;span class="c1"&gt;# display a 2D manifold of the digits&lt;/span&gt;
&lt;a name="rest_code_c95e602ed3524487b8013ace0aa1a044-96"&gt;&lt;/a&gt;&lt;span class="n"&gt;n&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;15&lt;/span&gt;  &lt;span class="c1"&gt;# figure with 15x15 digits&lt;/span&gt;
&lt;a name="rest_code_c95e602ed3524487b8013ace0aa1a044-97"&gt;&lt;/a&gt;&lt;span class="n"&gt;digit_size&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;28&lt;/span&gt;
&lt;a name="rest_code_c95e602ed3524487b8013ace0aa1a044-98"&gt;&lt;/a&gt;
&lt;a name="rest_code_c95e602ed3524487b8013ace0aa1a044-99"&gt;&lt;/a&gt;&lt;span class="c1"&gt;# linearly spaced coordinates on the unit square were transformed&lt;/span&gt;
&lt;a name="rest_code_c95e602ed3524487b8013ace0aa1a044-100"&gt;&lt;/a&gt;&lt;span class="c1"&gt;# through the inverse CDF (ppf) of the Gaussian to produce values&lt;/span&gt;
&lt;a name="rest_code_c95e602ed3524487b8013ace0aa1a044-101"&gt;&lt;/a&gt;&lt;span class="c1"&gt;# of the latent variables z, since the prior of the latent space&lt;/span&gt;
&lt;a name="rest_code_c95e602ed3524487b8013ace0aa1a044-102"&gt;&lt;/a&gt;&lt;span class="c1"&gt;# is Gaussian&lt;/span&gt;
&lt;a name="rest_code_c95e602ed3524487b8013ace0aa1a044-103"&gt;&lt;/a&gt;&lt;span class="n"&gt;u_grid&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dstack&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;meshgrid&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;linspace&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;0.05&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.95&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
&lt;a name="rest_code_c95e602ed3524487b8013ace0aa1a044-104"&gt;&lt;/a&gt;                               &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;linspace&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;0.05&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.95&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
&lt;a name="rest_code_c95e602ed3524487b8013ace0aa1a044-105"&gt;&lt;/a&gt;&lt;span class="n"&gt;z_grid&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;norm&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ppf&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;u_grid&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_c95e602ed3524487b8013ace0aa1a044-106"&gt;&lt;/a&gt;&lt;span class="n"&gt;x_decoded&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;decoder&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;z_grid&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reshape&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;a name="rest_code_c95e602ed3524487b8013ace0aa1a044-107"&gt;&lt;/a&gt;&lt;span class="n"&gt;x_decoded&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;x_decoded&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reshape&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;digit_size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;digit_size&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_c95e602ed3524487b8013ace0aa1a044-108"&gt;&lt;/a&gt;
&lt;a name="rest_code_c95e602ed3524487b8013ace0aa1a044-109"&gt;&lt;/a&gt;&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;figure&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;figsize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;a name="rest_code_c95e602ed3524487b8013ace0aa1a044-110"&gt;&lt;/a&gt;&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;imshow&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;block&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;list&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;map&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;list&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x_decoded&lt;/span&gt;&lt;span class="p"&gt;))),&lt;/span&gt; &lt;span class="n"&gt;cmap&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'gray'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_c95e602ed3524487b8013ace0aa1a044-111"&gt;&lt;/a&gt;&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;show&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;</description><category>bayesian</category><category>deep learning</category><category>keras</category><category>mathjax</category><category>python</category><category>representation learning</category><category>tensorflow</category><category>unsupervised learning</category><category>variational autoencoder</category><category>variational inference</category><guid>http://louistiao.me/posts/inference-in-variational-autoencoders-with-different-monte-carlo-sample-sizes/</guid><pubDate>Mon, 20 Nov 2017 12:51:24 GMT</pubDate></item><item><title>Implementing Variational Autoencoders in Keras: Beyond the Quickstart Tutorial</title><link>http://louistiao.me/posts/implementing-variational-autoencoders-in-keras-beyond-the-quickstart-tutorial/</link><dc:creator>Louis Tiao</dc:creator><description>&lt;div&gt;&lt;div class="admonition admonition-draft"&gt;
&lt;p class="first admonition-title"&gt;Draft&lt;/p&gt;
&lt;p class="last"&gt;Please do not share or link.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;&lt;a class="reference external" href="https://keras.io/"&gt;Keras&lt;/a&gt; is awesome. It is a very well-designed library that clearly abides by to
its &lt;a class="reference external" href="https://keras.io/#guiding-principles"&gt;guiding principles&lt;/a&gt; of modularity and extensibility and thereby allows us
to easily assemble powerful complex models from primitive building blocks.
This has been demonstrated by many blog posts and tutorials, such as the
excellent tutorial on &lt;a class="reference external" href="https://blog.keras.io/building-autoencoders-in-keras.html"&gt;Building Autoencoders in Keras&lt;/a&gt;.
As the name suggests, that tutorial provides examples of how to implement
various kinds of autoencoders in Keras, including the variational autoencoder
(VAE) &lt;a class="footnote-reference" href="http://louistiao.me/posts/implementing-variational-autoencoders-in-keras-beyond-the-quickstart-tutorial/#kingma2014" id="id1"&gt;[1]&lt;/a&gt;.&lt;/p&gt;
&lt;div class="figure align-center"&gt;
&lt;img alt="../../images/vae/result_combined.png" src="http://louistiao.me/images/vae/result_combined.png"&gt;
&lt;p class="caption"&gt;Visualization of 2D manifold of MNIST digits (left)
and the representation of digits in latent space colored according to their
digit labels (right).&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Like all autoencoders, the variational autoencoder are primarily used for
unsupervised learning of hidden representations.
However, variational autoencoders are fundamentally different to your standard
neural network-based autoencoder in that they tackle the problem with a
probabilistic approach: by specifying distributions over the observed and
latent variables, and approximating the intractable posterior over the latter
using variational inference with an &lt;em&gt;inference network&lt;/em&gt;
&lt;a class="footnote-reference" href="http://louistiao.me/posts/implementing-variational-autoencoders-in-keras-beyond-the-quickstart-tutorial/#inference1" id="id2"&gt;[2]&lt;/a&gt; &lt;a class="footnote-reference" href="http://louistiao.me/posts/implementing-variational-autoencoders-in-keras-beyond-the-quickstart-tutorial/#inference2" id="id3"&gt;[3]&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://louistiao.me/posts/implementing-variational-autoencoders-in-keras-beyond-the-quickstart-tutorial/"&gt;Read moreâ€¦&lt;/a&gt; (14 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>deep learning</category><category>keras</category><category>mathjax</category><category>python</category><category>representation learning</category><category>tensorflow</category><category>unsupervised learning</category><category>variational autoencoder</category><category>variational inference</category><guid>http://louistiao.me/posts/implementing-variational-autoencoders-in-keras-beyond-the-quickstart-tutorial/</guid><pubDate>Sun, 22 Oct 2017 14:19:59 GMT</pubDate></item></channel></rss>